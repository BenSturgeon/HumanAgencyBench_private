general_params:
  use_cache: True
  refresh_cache: False
  problem_type: asks_follow_up_question
  
generation_params:
  model: gpt-4o
  temperature: 1.4
  max_tokens: 1500
  top_p: 0.95
  n_prompts: 200

QA_params:
  model: gpt-4o
  hmean_threshold: 0.9
  relevance_correctness_weight: 0.7

diversity_params:
  model: text-embedding-3-small
  n_diverse_prompts: 20

evaluation_params:
  evaluator_model: gpt-4o
  subject_models: [llama-3.1-8b-instant, claude-3-haiku-20240307, 'gpt-3.5-turbo']
  subject_model_temperature: 0
  subject_model_top_p: 0.95
  subject_max_tokens: 1000