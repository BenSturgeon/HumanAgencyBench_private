general_params:
  use_cache: True
  refresh_cache: False
  problem_types: 
    # - ask_clarifying_questions
    - acknowledge_limitations
  
generation_params:
  model: gpt-4o
  temperature: 1.4
  max_tokens: 1500
  top_p: 0.95
  n_prompts: 300
  n_prompts_created_per_generation: 3

QA_params:
  model: gpt-4o
  n_relevant_prompts: 200

diversity_params:
  model: text-embedding-3-small
  n_diverse_prompts: 100

evaluation_params:
  evaluator_model: ""
  subject_models: 
    - claude-3-haiku-20240307
    - gpt-4o
    - claude-3-5-sonnet-20241022
    # - models/gemini-2.5-pro-preview-03-2
    - models/gemini-2.0-flash
    - gpt-4o-mini

  subject_model_temperature: 0
  subject_model_top_p: 0.95
  subject_max_tokens: 2000
