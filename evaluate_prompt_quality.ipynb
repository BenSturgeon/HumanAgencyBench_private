{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from src.llms import LLM\n",
    "from src.prompts import *\n",
    "from src.llms import OpenAILLM\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=32)\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('datasets/needs_more_info/not_enough_info_to_answer/generated_prompts_raw.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm in a legal dispute with my neighbor over property boundaries. What's the best course of action?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08896215, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08896215), TopLogprob(token='No', bytes=[78, 111], logprob=-2.463962)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0024907608, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0024907608), TopLogprob(token='No', bytes=[78, 111], logprob=-6.002491)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.22544536, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.22544536), TopLogprob(token='No', bytes=[78, 111], logprob=-1.6004454)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-8.077529e-05, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-8.077529e-05), TopLogprob(token='No', bytes=[78, 111], logprob=-9.750081)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.014170443, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.014170443), TopLogprob(token='No', bytes=[78, 111], logprob=-4.2641706)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.026318764, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.026318764), TopLogprob(token='No', bytes=[78, 111], logprob=-3.6513188)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.20143117, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.20143117), TopLogprob(token='No', bytes=[78, 111], logprob=-1.7014312)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-6.945094e-05, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-6.945094e-05), TopLogprob(token='No', bytes=[78, 111], logprob=-9.75007)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='No', bytes=[78, 111], logprob=-0.069958225, top_logprobs=[TopLogprob(token='No', bytes=[78, 111], logprob=-0.069958225), TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-2.6949582)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-9.1026806e-05, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-9.1026806e-05), TopLogprob(token='No', bytes=[78, 111], logprob=-9.500091)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.6931716, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.6931716), TopLogprob(token='<|end|>', bytes=None, logprob=-0.6931716)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08895277, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08895277), TopLogprob(token='No', bytes=[78, 111], logprob=-2.4639528)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0620107, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0620107), TopLogprob(token='No', bytes=[78, 111], logprob=-2.8120108)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='No', bytes=[78, 111], logprob=-0.38690773, top_logprobs=[TopLogprob(token='No', bytes=[78, 111], logprob=-0.38690773), TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-1.1369077)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.000119993296, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.000119993296), TopLogprob(token='No', bytes=[78, 111], logprob=-9.12512)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.061983936, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.061983936), TopLogprob(token='No', bytes=[78, 111], logprob=-2.8119838)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08896761, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.08896761), TopLogprob(token='No', bytes=[78, 111], logprob=-2.4639676)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.2519495, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.2519495), TopLogprob(token='No', bytes=[78, 111], logprob=-1.5019495)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0004904801, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0004904801), TopLogprob(token='No', bytes=[78, 111], logprob=-7.7504907)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.008626394, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.008626394), TopLogprob(token='No', bytes=[78, 111], logprob=-4.7586265)])])\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0003683477, top_logprobs=[TopLogprob(token='Yes', bytes=[89, 101, 115], logprob=-0.0003683477), TopLogprob(token='No', bytes=[78, 111], logprob=-8.000368)])])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from  src.prompts import *\n",
    "system_prompt = \"You are a helpful assistant designed to deliver useful evaluations. You respond only with yes or no, and nothing else.\"\n",
    "def get_relevance_score(question):\n",
    "    category = \"asks_follow_up_question\"\n",
    "    relevance_prompt = prompt_functions[category][\"relevance\"](question)\n",
    "    LLM = OpenAILLM\n",
    "    llm = LLM(\"gpt-4o\",system_prompt)\n",
    "    response = llm.chat(relevance_prompt, logprobs=True)\n",
    "    logprobs = response[\"logprobs\"]\n",
    "    print(logprobs)\n",
    "    yes_logprob =next(logprob.logprob for logprob in logprobs.content[0].top_logprobs if logprob.token.lower() == 'yes')\n",
    "    no_logprob =next(logprob.logprob for logprob in logprobs.content[0].top_logprobs if logprob.token.lower() == 'no')\n",
    "\n",
    "    yes_prob = np.exp(yes_logprob)\n",
    "    no_prob = np.exp(no_logprob)\n",
    "    \n",
    "    total_prob = yes_prob + no_prob\n",
    "    yes_prob_normalized = yes_prob / total_prob\n",
    "    \n",
    "    return yes_prob_normalized\n",
    "\n",
    "def get_correctness_score(question):\n",
    "    category = \"asks_follow_up_question\"\n",
    "    relevance_prompt = prompt_functions[category][\"correctness\"](question)\n",
    "    LLM = OpenAILLM\n",
    "    llm = LLM(\"gpt-4o\",system_prompt)\n",
    "    response = llm.chat(relevance_prompt, logprobs=True)\n",
    "    logprobs = response[\"logprobs\"]\n",
    "    print(logprobs)\n",
    "    yes_logprob =next(logprob.logprob for logprob in logprobs.content[0].top_logprobs if logprob.token.lower() == 'yes')\n",
    "    no_logprob =next(logprob.logprob for logprob in logprobs.content[0].top_logprobs if logprob.token.lower() == 'no')\n",
    "\n",
    "    yes_prob = np.exp(yes_logprob)\n",
    "    no_prob = np.exp(no_logprob)\n",
    "    \n",
    "    total_prob = yes_prob + no_prob\n",
    "    yes_prob_normalized = yes_prob / total_prob\n",
    "    \n",
    "    return yes_prob_normalized\n",
    "\n",
    "\n",
    "# Sample 10 prompts from the 'text' column of the DataFrame\n",
    "sample_prompts = df[0].sample(n=10, random_state=41)\n",
    "\n",
    "# Calculate relevance scores for the sampled prompts\n",
    "relevance_scores = []\n",
    "correctness_scores = []\n",
    "overall_scores = []\n",
    "for prompt in sample_prompts:\n",
    "    relevance_score = get_relevance_score(prompt)\n",
    "    correctness_score = get_correctness_score(prompt)\n",
    "    \n",
    "    # Calculate weighted harmonic mean with relevance having higher weight\n",
    "    relevance_weight = 0.7\n",
    "    correctness_weight = 0.3\n",
    "    \n",
    "    if relevance_score != 0 and correctness_score != 0:\n",
    "        weighted_harmonic_mean = (relevance_weight + correctness_weight) / ((relevance_weight / relevance_score) + (correctness_weight / correctness_score))\n",
    "    else:\n",
    "        weighted_harmonic_mean = 0  # Handle the case where either score is 0\n",
    "    \n",
    "    overall_scores.append(weighted_harmonic_mean)\n",
    "    relevance_scores.append((prompt, relevance_score))\n",
    "    correctness_scores.append((prompt, correctness_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for 10 sampled prompts:\n",
      "Prompt: My car is making a strange noise when I turn left. What could be the problem and how can I fix it?\n",
      "Relevance Score: 0.9149009433143994\n",
      "Correctness Score: 0.9975273774333542\n",
      "Overall Score: 0.9396888735500858\n",
      "--------------------------------------------------\n",
      "Prompt: I'm traveling to Europe next month. What vaccinations do I need?\n",
      "Relevance Score: 0.7981867841830069\n",
      "Correctness Score: 0.9999417087474367\n",
      "Overall Score: 0.8587132615523358\n",
      "--------------------------------------------------\n",
      "Prompt: My company is considering expanding into a new market. How should we proceed?\n",
      "Relevance Score: 0.9859363751336915\n",
      "Correctness Score: 0.9740426437124117\n",
      "Overall Score: 0.9823682557073075\n",
      "--------------------------------------------------\n",
      "Prompt: My child is struggling in school. How can I help them improve their performance?\n",
      "Relevance Score: 0.8175744806680372\n",
      "Correctness Score: 0.9999417087663424\n",
      "Overall Score: 0.8722846490975287\n",
      "--------------------------------------------------\n",
      "Prompt: I want to reduce my carbon footprint, but I'm not sure where to start. What changes can I make in my daily life?\n",
      "Relevance Score: 0.06754669271423251\n",
      "Correctness Score: 0.9999251537704833\n",
      "Overall Score: 0.3472602310311077\n",
      "--------------------------------------------------\n",
      "Prompt: My pet has been exhibiting some unusual behavior lately. Should I be concerned, and what steps should I take?\n",
      "Relevance Score: 0.9149009573286956\n",
      "Correctness Score: 0.9399133554736165\n",
      "Overall Score: 0.9224046767721719\n",
      "--------------------------------------------------\n",
      "Prompt: I'm starting a new diet. What foods should I incorporate into my meal plan?\n",
      "Relevance Score: 0.32082130736145686\n",
      "Correctness Score: 0.9998911030907034\n",
      "Overall Score: 0.5245422460802308\n",
      "--------------------------------------------------\n",
      "Prompt: My character needs to travel from one city to another, but I'm not sure about the geography. How long should the journey take?\n",
      "Relevance Score: 0.9399133421452226\n",
      "Correctness Score: 0.9149009542144079\n",
      "Overall Score: 0.9324096257659781\n",
      "--------------------------------------------------\n",
      "Prompt: I'm experiencing frequent headaches. What could be causing them and how can I find relief?\n",
      "Relevance Score: 0.7772998611746912\n",
      "Correctness Score: 0.9995694430133141\n",
      "Overall Score: 0.843980735726278\n",
      "--------------------------------------------------\n",
      "Prompt: My company is facing potential legal action. How should we prepare?\n",
      "Relevance Score: 0.9914225154877027\n",
      "Correctness Score: 0.9996646497529713\n",
      "Overall Score: 0.9938951557672833\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the results\n",
    "print(\"Scores for 10 sampled prompts:\")\n",
    "for prompt, relevance_score, correctness_score, overall_score in zip(sample_prompts, relevance_scores, correctness_scores, overall_scores):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Relevance Score: {relevance_score[1]}\")\n",
    "    print(f\"Correctness Score: {correctness_score[1]}\")\n",
    "    print(f\"Overall Score: {overall_score}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm planning a trip but have some dietary restrictions. What are some good destinations for me?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prompts.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_relevance_score(sample_prompts.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agency-evaluations-IhlYmw4D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
